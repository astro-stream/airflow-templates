{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "def camel_case_split(operator_str):\n",
    " \n",
    "    op_list = re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', operator_str)\n",
    "    \n",
    "    return ' '.join(op_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = ['apache-airflow-providers-airbyte',\n",
    "    'apache-airflow-providers-alibaba',\n",
    "    'apache-airflow-providers-amazon',\n",
    "    'apache-airflow-providers-apache-beam',\n",
    "    'apache-airflow-providers-apache-cassandra',\n",
    "    'apache-airflow-providers-apache-drill',\n",
    "    'apache-airflow-providers-apache-druid',\n",
    "    'apache-airflow-providers-apache-hdfs',\n",
    "    'apache-airflow-providers-apache-hive',\n",
    "    'apache-airflow-providers-apache-kylin',\n",
    "    'apache-airflow-providers-apache-livy',\n",
    "    'apache-airflow-providers-apache-pig',\n",
    "    'apache-airflow-providers-apache-pinot',\n",
    "    'apache-airflow-providers-apache-spark',\n",
    "    'apache-airflow-providers-apache-sqoop',\n",
    "    'apache-airflow-providers-arangodb',\n",
    "    'apache-airflow-providers-asana',\n",
    "    'apache-airflow-providers-atlassian-jira',\n",
    "    'apache-airflow-providers-celery',\n",
    "    'apache-airflow-providers-cloudant',\n",
    "    'apache-airflow-providers-cncf-kubernetes',\n",
    "    'apache-airflow-providers-common-sql',\n",
    "    'apache-airflow-providers-databricks',\n",
    "    'apache-airflow-providers-datadog',\n",
    "    'apache-airflow-providers-dbt-cloud',\n",
    "    'apache-airflow-providers-dingding',\n",
    "    'apache-airflow-providers-discord',\n",
    "    'apache-airflow-providers-docker',\n",
    "    'apache-airflow-providers-elasticsearch',\n",
    "    'apache-airflow-providers-exasol',\n",
    "    'apache-airflow-providers-facebook',\n",
    "    'apache-airflow-providers-ftp',\n",
    "    'apache-airflow-providers-github',\n",
    "    'apache-airflow-providers-google',\n",
    "    'apache-airflow-providers-grpc',\n",
    "    'apache-airflow-providers-hashicorp',\n",
    "    'apache-airflow-providers-http',\n",
    "    'apache-airflow-providers-imap',\n",
    "    'apache-airflow-providers-influxdb',\n",
    "    'apache-airflow-providers-jdbc',\n",
    "    'apache-airflow-providers-jenkins',\n",
    "    'apache-airflow-providers-microsoft-azure',\n",
    "    'apache-airflow-providers-microsoft-mssql',\n",
    "    'apache-airflow-providers-microsoft-psrp',\n",
    "    'apache-airflow-providers-microsoft-winrm',\n",
    "    'apache-airflow-providers-mongo',\n",
    "    'apache-airflow-providers-mysql',\n",
    "    'apache-airflow-providers-neo4j',\n",
    "    'apache-airflow-providers-odbc',\n",
    "    'apache-airflow-providers-openfaas',\n",
    "    'apache-airflow-providers-opsgenie',\n",
    "    'apache-airflow-providers-oracle',\n",
    "    'apache-airflow-providers-pagerduty',\n",
    "    'apache-airflow-providers-papermill',\n",
    "    'apache-airflow-providers-plexus',\n",
    "    'apache-airflow-providers-postgres',\n",
    "    'apache-airflow-providers-presto',\n",
    "    'apache-airflow-providers-qubole',\n",
    "    'apache-airflow-providers-redis',\n",
    "    'apache-airflow-providers-salesforce',\n",
    "    'apache-airflow-providers-samba',\n",
    "    'apache-airflow-providers-segment',\n",
    "    'apache-airflow-providers-sendgrid',\n",
    "    'apache-airflow-providers-sftp',\n",
    "    'apache-airflow-providers-singularity',\n",
    "    'apache-airflow-providers-slack',\n",
    "    'apache-airflow-providers-snowflake',\n",
    "    'apache-airflow-providers-sqlite',\n",
    "    'apache-airflow-providers-ssh',\n",
    "    'apache-airflow-providers-tableau',\n",
    "    'apache-airflow-providers-tabular',\n",
    "    'apache-airflow-providers-telegram',\n",
    "    'apache-airflow-providers-trino',\n",
    "    'apache-airflow-providers-vertica',\n",
    "    'apache-airflow-providers-yandex',\n",
    "    'apache-airflow-providers-zendesk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mods = []\n",
    "# operator_all = []\n",
    "# base_url = 'airflow.apache.org/docs'\n",
    "# for package in ['apache-airflow-providers-amazon']:\n",
    "#     company = package.split('-')[-2]\n",
    "#     detail = package.split('-')[-1]\n",
    "#     if len(package.split('-')) > 4:\n",
    "#         url_owner = f\"{company}/{detail}\"\n",
    "#         id_owner = f\"{company}.{detail}\"\n",
    "#     provider_url = f'https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/_api/airflow/providers/amazon/index.html'\n",
    "#     req = requests.get(provider_url)\n",
    "#     if len(req.text) > 0 and req.status_code == 200:\n",
    "#         print(f'URL:{provider_url}')\n",
    "#         soup = BeautifulSoup(req.text, 'html.parser')\n",
    "#         modules = soup.find_all('div', {'class':'section', 'id': f'module-airflow.providers.amazon'})\n",
    "#         depth = len(modules[0].find_all('div', {'class':'toctree-wrapper compound'})[0].find('ul'))\n",
    "#         sub_modules = modules[0].find_all('div', {'class':'toctree-wrapper compound'})\n",
    "#         uls = sub_modules[0].find_all('ul')\n",
    "#         top_ul = uls[0].find_all('ul')\n",
    "#         tree_depth = top_ul[-1].find_all('li')[0].get('class')[0]\n",
    "#         mod_packages = sub_modules[0].find_all('li', {'class':tree_depth})\n",
    "#         for mod in mod_packages:\n",
    "#             mod_str = str(mod.string)\n",
    "#             print(mod_str)\n",
    "\n",
    "#             if 'operator' in mod_str and mod_str !='airflow.providers.google.cloud.operators.vertex_ai':\n",
    "\n",
    "#                 operator_base = mod_str.replace('airflow.providers.','').replace('.','/').replace('aws_lambda','lambda_function')\n",
    "#                 provider_base = mod_str.split('.')[2]\n",
    "#                 operator_class_base = operator_base.replace('/', '.')\n",
    "\n",
    "#                 op_url = f'https://{base_url}/{package}/stable/_api/airflow/providers/{operator_base}/index.html'\n",
    "\n",
    "#                 # airflow.providers.alibaba.cloud.operators.oss\n",
    "#                 op_res = requests.get(op_url)\n",
    "#                 # print(op_res.text)\n",
    "#                 operator_soup = BeautifulSoup(op_res.text, 'html.parser')\n",
    "#                 operator_classes = operator_soup.find_all('table', {'class': 'autosummary longtable docutils align-default'})\n",
    "#                 operators = operator_classes[0].find_all('a', {'class': 'reference internal'})\n",
    "#                 for operator in operators:\n",
    "#                     print(operator)\n",
    "#                     op_name = operator_class_base.split('.')[0]\n",
    "#                     operator_class = f\"airflow.providers.{operator_class_base}.{operator.string}\"\n",
    "#                     # airflow.providers.alibaba.cloud.operators.oss.OSSCreateBucketOperator\n",
    "#                     # print(operator_class)\n",
    "\n",
    "#                     operator_div = operator_soup.find_all(\"dt\", {\"class\": \"sig sig-object py\", \"id\":operator_class})\n",
    "#                     operator_divs = operator_div[0].find_all(\"em\", {\"class\": \"sig-param\"})\n",
    "\n",
    "#                     operator_list = []\n",
    "\n",
    "#                     arg_default_val =\"\"\n",
    "#                     for i in operator_divs[:-1]:\n",
    "#                         # print(operator_divs, arg)\n",
    "#                         arg = i.find(\"span\", {\"class\":\"pre\"}).string\n",
    "#                         try: \n",
    "#                             if i.find(\"span\", {\"class\":\"default_value\"}):\n",
    "#                                 arg_default_val = i.find(\"span\", {\"class\":\"default_value\"}).string.replace(\"'\", '*')\n",
    "#                         except:\n",
    "#                             pass\n",
    "\n",
    "#                         arg_vals = f\"\\t{arg}={arg_default_val},\" if arg_default_val != \"\" else f\"\\t{arg},\"\n",
    "#                         operator_list.append(arg_vals)\n",
    "                        \n",
    "                        \n",
    "#                     operator_name = operator.string\n",
    "                    \n",
    "#                     operator_list.insert(0,f\"{operator_name}_task = {operator_name}(\")\n",
    "#                     operator_list.insert(1,f\"\\ttask_id=*{operator_name}_task*\")\n",
    "#                     operator_list.extend(\")\")\n",
    "#                     operator_list.insert(0,op_name)\n",
    "#                     # print(operator_list)\n",
    "                    \n",
    "#                     operator_all.append(operator_list)\n",
    "                    \n",
    "\n",
    "\n",
    "#                 mods.append(str(mod.string))\n",
    "\n",
    "#     else:\n",
    "#         print(f'No text found on page:  URL:{provider_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = []\n",
    "operator_all = []\n",
    "base_url = 'airflow.apache.org/docs'\n",
    "for package in providers[1:]:\n",
    "    company = package.split('-')[-2]\n",
    "    detail = package.split('-')[-1]\n",
    "    if len(package.split('-')) > 4:\n",
    "        url_owner = f\"{company}/{detail}\"\n",
    "        id_owner = f\"{company}.{detail}\"\n",
    "    else:\n",
    "        url_owner, id_owner = detail,detail\n",
    "    provider_url = f'https://{base_url}/{package}/stable/_api/airflow/providers/{url_owner}/index.html'\n",
    "    req = requests.get(provider_url)\n",
    "    if len(req.text) > 0 and req.status_code == 200:\n",
    "        print(f'Provider: {url_owner}, ID:{id_owner}, URL:{provider_url}')\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        modules = soup.find_all('div', {'class':'section', 'id': f'module-airflow.providers.{id_owner}'})\n",
    "        depth = len(modules[0].find_all('div', {'class':'toctree-wrapper compound'})[0].find('ul'))\n",
    "        sub_modules = modules[0].find_all('div', {'class':'toctree-wrapper compound'})\n",
    "        uls = sub_modules[0].find_all('ul')\n",
    "        top_ul = uls[0].find_all('ul')\n",
    "        tree_depth = top_ul[-1].find_all('li')[0].get('class')[0]\n",
    "        mod_packages = sub_modules[0].find_all('li', {'class':tree_depth})\n",
    "        for mod in mod_packages:\n",
    "            mod_str = str(mod.string)\n",
    "\n",
    "            if 'operator' in mod_str and mod_str !='airflow.providers.google.cloud.operators.vertex_ai':\n",
    "\n",
    "                operator_base = mod_str.replace('airflow.providers.','').replace('.','/').replace('aws_lambda','lambda_function')\n",
    "                provider_base = mod_str.split('.')[2]\n",
    "                operator_class_base = operator_base.replace('/', '.')\n",
    "\n",
    "                op_url = f'https://{base_url}/{package}/stable/_api/airflow/providers/{operator_base}/index.html'\n",
    "\n",
    "                # airflow.providers.alibaba.cloud.operators.oss\n",
    "                op_res = requests.get(op_url)\n",
    "                # print(op_res.text)\n",
    "                operator_soup = BeautifulSoup(op_res.text, 'html.parser')\n",
    "                operator_classes = operator_soup.find_all('table', {'class': 'autosummary longtable docutils align-default'})\n",
    "                # operators = operator_classes[0].find_all('span', {'class': 'pre'})\n",
    "                operators = operator_classes[0].find_all('a', {'class': 'reference internal'})\n",
    "                for operator in operators:\n",
    "                    op_name = operator_class_base.split('.')[0]\n",
    "                    operator_class = f\"airflow.providers.{operator_class_base}.{operator.string}\"\n",
    "                    # airflow.providers.alibaba.cloud.operators.oss.OSSCreateBucketOperator\n",
    "                    # print(operator_class)\n",
    "\n",
    "                    operator_div = operator_soup.find_all(\"dt\", {\"class\": \"sig sig-object py\", \"id\":operator_class})\n",
    "                    operator_divs = operator_div[0].find_all(\"em\", {\"class\": \"sig-param\"})\n",
    "\n",
    "                    operator_list = []\n",
    "\n",
    "                    arg_default_val =\"\"\n",
    "                    for i in operator_divs[:-1]:\n",
    "                        # print(operator_divs, arg)\n",
    "                        arg = i.find(\"span\", {\"class\":\"pre\"}).string\n",
    "                        if arg == \"*\":\n",
    "                            continue\n",
    "                        try: \n",
    "                            if i.find(\"span\", {\"class\":\"default_value\"}):\n",
    "                                arg_default_val = i.find(\"span\", {\"class\":\"default_value\"}).string.replace(\"'\", '*')\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                        arg_vals = f\"\\t{arg}={arg_default_val},\" if arg_default_val != \"\" else f\"\\t{arg},\"\n",
    "                        operator_list.append(arg_vals)\n",
    "                        \n",
    "                        \n",
    "                    operator_name = operator.string\n",
    "                    \n",
    "                    operator_list.insert(0,f\"\\t{operator_name}_task = {operator_name}(\")\n",
    "                    operator_list.insert(1,f\"\\ttask_id=*{operator_name}_task*,\")\n",
    "                    operator_list.append(\"\\t)\")\n",
    "                    operator_list.insert(0,op_name)\n",
    "                    # print(operator_list)\n",
    "                    \n",
    "                    operator_all.append(operator_list)\n",
    "                    \n",
    "    \n",
    "\n",
    "                mods.append(str(mod.string))\n",
    "    else:\n",
    "        print(f'No text found on page: Provider: {url_owner} URL:{provider_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in operator_all:\n",
    "\n",
    "    operator_name = op[1].split(' ')[0].replace('_task', '').replace('\\t','')\n",
    "    operator_prefix = f\"{op[0]} {camel_case_split(str(operator_name)) }\"\n",
    "    print(operator_name, operator_prefix)\n",
    "    \n",
    "    operator_dict = {operator_name: {\"prefix\": operator_prefix.capitalize(),\"body\":op[1:]}}\n",
    "\n",
    "    # p1 = str(operator_dict), ','\n",
    "    operator_replaced_dict = str(operator_dict).replace(\"'\", '\"').replace(\"*\", \"\\'\").replace('\"[', '[').replace(']\"', ']')\n",
    "    operator_file_append = operator_replaced_dict[1:-1]+','\n",
    "\n",
    "    file_path = f'{os.getcwd()}/snippets/snippets.code-snippets'\n",
    "\n",
    "    f = open(file_path, \"a\")\n",
    "    f.write(operator_file_append+'\\n')\n",
    "    f.close()\n",
    "\n",
    "end_f = open(file_path, \"a\")\n",
    "end_f.write(\"}\")\n",
    "end_f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
